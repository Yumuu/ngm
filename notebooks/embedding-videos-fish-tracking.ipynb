{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array as ar\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from skimage.io import imread\n",
    "from multiprocessing import Pool, cpu_count\n",
    "%matplotlib inline\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyqtgraph as pq\n",
    "%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paths = ['/groups/ahrens/ahrenslab/davis/data/epi/20170621/6dpf_cy221xcy221_f1_spon_1/Pos0/',\n",
    "        '/groups/ahrens/ahrenslab/davis/data/epi/20170621/6dpf_cy221xcy221_f1_spon_2/Pos0/'\n",
    "        '/groups/ahrens/ahrenslab/davis/data/epi/20170621/6dpf_cy221xcy221_f2_spon_1/Pos0/',\n",
    "        '/groups/ahrens/ahrenslab/davis/data/epi/20170621/6dpf_cy221xcy221_f2_spon_2/Pos0/',\n",
    "        '/groups/ahrens/ahrenslab/davis/data/epi/20170621/6dpf_cy221xcy221_f5_spon_1_1/Pos0/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "im_fnames = [glob(d + '*.tif') for d in paths]\n",
    "[imf.sort() for imf in im_fnames]\n",
    "print(len(im_fnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wipe_ims(pq):\n",
    "    from numpy import zeros\n",
    "    for iw in pq.images:\n",
    "      iw.setImage(zeros((1,1))) #<- dummy 1x1 image\n",
    "      iw.parent().close()\n",
    "\n",
    "def mem_use():\n",
    "    import os\n",
    "    import psutil\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memory_use = py.memory_info()[0]/2.**30  # memory use in GB...I think\n",
    "    return memory_use\n",
    "\n",
    "def pool_wrapper(function, data, num_cores, mode='map'):\n",
    "    from multiprocessing import Pool\n",
    "    with Pool(num_cores) as p:\n",
    "        try:\n",
    "            if mode == 'map':\n",
    "                result = p.map(function, data)\n",
    "            elif mode == 'starmap':\n",
    "                result = p.starmap(function, data)\n",
    "        except Exception as inst:\n",
    "            print('There was a problem!')\n",
    "            print(inst)\n",
    "            return None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.5 s, sys: 23.4 s, total: 32.9 s\n",
      "Wall time: 44.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "multicore = True\n",
    "to_load = -1\n",
    "plr = slice(0,None)\n",
    "num_cores = 16\n",
    "\n",
    "if multicore:\n",
    "    ims = np.array(pool_wrapper(imread, im_fnames[to_load][plr], num_cores))\n",
    "else:\n",
    "    ims = ar([imread(imf) for imf in im_fnames[to_load][plr]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.553890228271484"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a mask for the fish\n",
    "def get_fish_mask(im, sigma=4, shrink_factor=.1, min_size=400, disk_size=14, return_sparse=True):\n",
    "    from numpy import abs\n",
    "    im_ = im.copy().astype('float32')\n",
    "    # remove background\n",
    "    im_bgr = remove_background(im, sigma=sigma)\n",
    "    # estimate a threshold on the background-removed image\n",
    "    thr = simple_threshold(im_bgr, shrink_factor=shrink_factor)\n",
    "    # remove speckles of the absolute value of the background-subtracted image    \n",
    "    binarized = despeckle_morph(abs(im_bgr) > thr, min_size=min_size)\n",
    "    binarized_2 = binarized.copy()\n",
    "    \n",
    "    if binarized.any():\n",
    "        # expand the mask\n",
    "        dilated = disk_dilate(binarized, disk_size=disk_size)\n",
    "        # threshold in the original image\n",
    "        thr_2 = simple_threshold(im_[dilated], nbins=300)\n",
    "        # remove speckles\n",
    "        binarized_2 = despeckle_morph((im_ * dilated) > thr_2, min_size=min_size)      \n",
    "    \n",
    "    if return_sparse:\n",
    "        from scipy.sparse import coo_matrix\n",
    "        binarized_2 = coo_matrix(binarized_2)\n",
    "        \n",
    "    return binarized_2\n",
    "\n",
    "def simple_threshold(data, shrink_factor=.1, nbins=3000):\n",
    "    from numpy import histogram, argmax, where, median, argmin\n",
    "    counts, bins = histogram(data.ravel(), bins=nbins)\n",
    "    pk = median(data)\n",
    "    pk_ind = argmin(abs(bins - pk))\n",
    "    pk_counts = counts[pk_ind-1]\n",
    "    right_tail = where(counts[pk_ind:] < (pk_counts * shrink_factor))[0]\n",
    "    if len(right_tail) > 0:\n",
    "        right_foot = right_tail[0] + pk_ind \n",
    "    else:\n",
    "        right_foot = -1\n",
    "    return bins[right_foot]\n",
    "\n",
    "def remove_background(im, sigma=4):\n",
    "    from scipy.ndimage.filters import gaussian_filter\n",
    "    im_ = im.copy().astype('float32')\n",
    "    return im_ - gaussian_filter(im_, sigma=sigma)\n",
    "\n",
    "def despeckle_morph(im, min_size=32):\n",
    "    from skimage.morphology import remove_small_objects\n",
    "    return remove_small_objects(im, min_size=min_size)\n",
    "\n",
    "# wrap binary dilation\n",
    "def disk_dilate(im, disk_size=8):\n",
    "    from skimage.morphology import disk, binary_dilation    \n",
    "    # execution time of binary dilation depends on size of the image so we can speed things up by cropping the image            \n",
    "    rmin, rmax, cmin, cmax = get_bbox(im, pad=disk_size//2)        \n",
    "    result = im.copy()\n",
    "    result[rmin:rmax, cmin:cmax] = binary_dilation(im[rmin:rmax, cmin:cmax], disk(disk_size))\n",
    "    return result\n",
    "\n",
    "# get the bounding box of a binary array with some padding\n",
    "def get_bbox(img, pad=0):\n",
    "    from numpy import any, where\n",
    "    rows = any(img, axis=1)\n",
    "    cols = any(img, axis=0)\n",
    "    rmin, rmax = where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = where(cols)[0][[0, -1]]\n",
    "\n",
    "    return rmin - pad, rmax + pad, cmin - pad, cmax + pad\n",
    "    \n",
    "\n",
    "# Remove the tail, leaving the brain\n",
    "# todo: make this function loop until a single object meeting a size criterion is found\n",
    "def get_brain(im, selem_size=6, object_size=200, return_sparse=True):\n",
    "    import warnings\n",
    "    from skimage.morphology import binary_opening, disk, remove_small_objects\n",
    "    from scipy.sparse import issparse\n",
    "    from numpy import array, zeros\n",
    "    \n",
    "    im_ = im.copy().astype('bool')\n",
    "    brain = zeros(im_.shape, dtype='bool')\n",
    "    \n",
    "    # if the input is sparse, make it dense\n",
    "    if issparse(im):\n",
    "        im_ = array(im_.todense())\n",
    "    \n",
    "    if not im_.any():        \n",
    "        if return_sparse:\n",
    "            from scipy.sparse import coo_matrix\n",
    "            brain = coo_matrix(brain)        \n",
    "        return brain\n",
    "    \n",
    "    rmin, rmax, cmin, cmax = get_bbox(im_, pad=selem_size//2)\n",
    "    \n",
    "    # remove_small_objects raises a warning if you give it a boolean array with one object     \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")    \n",
    "        im_[rmin:rmax, cmin:cmax] = binary_opening(im_[rmin:rmax, cmin:cmax], selem=disk(selem_size))\n",
    "        brain = remove_small_objects(im_, min_size=object_size)\n",
    "    \n",
    "    if return_sparse:\n",
    "        from scipy.sparse import coo_matrix\n",
    "        brain = coo_matrix(brain)\n",
    "        \n",
    "    return brain\n",
    "\n",
    "def cart2pol(x,y):\n",
    "    from numpy import hypot, arctan2\n",
    "    r = hypot(x,y)\n",
    "    phi = arctan2(y, x)\n",
    "    return r, phi\n",
    "\n",
    "def rotmat2d(phi):\n",
    "    from numpy import cos, sin, zeros\n",
    "    mat = zeros([2,2])\n",
    "    mat[0,0] = cos(phi)\n",
    "    mat[1,1] = cos(phi)\n",
    "    mat[0,1] = sin(phi)\n",
    "    mat[1,0] = -sin(phi)    \n",
    "    return mat\n",
    "\n",
    "def angle_difference(x,y):\n",
    "    from numpy import arctan2, sin, cos\n",
    "    return arctan2(sin(x-y), cos(x-y))\n",
    "\n",
    "def eig_wrapper(im):\n",
    "    from numpy import where, cov, argsort\n",
    "    import scipy.linalg as la\n",
    "            \n",
    "    y,x = np.where(im)\n",
    "    evals, evecs = la.eig(cov(x,y))\n",
    "    idx = argsort(evals)[::-1]\n",
    "    evals = evals[idx]\n",
    "    evecs = evecs[:,idx]\n",
    "    \n",
    "    return evals, evecs\n",
    "\n",
    "def affine_wrapper(image, rotation, c_in, c_out, order=1):\n",
    "    \"\"\"\n",
    "    Perform rotation followed by translation\n",
    "    \"\"\"\n",
    "    from scipy.ndimage.interpolation import affine_transform\n",
    "    offset = c_in - c_out.dot(rotation)\n",
    "    return affine_transform(image, rotation.T, offset=offset, mode='wrap', order=order)\n",
    "\n",
    "\n",
    "# todo: rotate a bounding box instead of the whole image\n",
    "def orient_tail(im, return_sparse=True):\n",
    "    # point the tail of the fish toward the origin, parallel to the x-axis\n",
    "    # im must be a binarized fish mask\n",
    "    from numpy import pi, rad2deg, isnan, array, zeros, round, roll, abs, argmin\n",
    "    from skimage.transform import rotate\n",
    "    from scipy.ndimage.measurements import center_of_mass\n",
    "    from scipy.ndimage.interpolation import shift\n",
    "    from scipy.sparse import issparse, coo_matrix\n",
    "\n",
    "    im_ = im.copy()\n",
    "    \n",
    "    if issparse(im_):\n",
    "        im_ = array(im_.todense())\n",
    "    \n",
    "    phi = 0\n",
    "    dydx = 0\n",
    "    \n",
    "    # if we can't find a fish or a brain, return all 0s\n",
    "    if not im_.any():\n",
    "        return coo_matrix(zeros(im_.shape, dtype='bool')), phi, dydx\n",
    "    \n",
    "    brain = get_brain(im_, return_sparse=False)\n",
    "    \n",
    "    # if we can't find a fish or a brain, return all 0s\n",
    "    if not brain.any():\n",
    "        output = zeros(im_.shape, dtype='bool')\n",
    "        if return_sparse:\n",
    "            output = coo_matrix(output)\n",
    "        return output, phi, dydx\n",
    "    \n",
    "    raw_com = array(center_of_mass(im_))\n",
    "    brain_com = array(center_of_mass(brain))    \n",
    "           \n",
    "    y_, x_ = brain_com\n",
    "    tail_y, tail_x = brain_com - raw_com\n",
    "    \n",
    "    brain_tail_angle = cart2pol(tail_x, tail_y)[-1]    \n",
    "        \n",
    "    # get the orietation of the long axis of the brain        \n",
    "    evals, evecs = eig_wrapper(brain)    \n",
    "    brain_angle = cart2pol(evecs[0,0], evecs[1,0])[-1]\n",
    "    candidate_phis = array([brain_angle, brain_angle + pi])\n",
    "    # Eigenvector of brain is ambiguous between tail to the left and tail to the right. Pick angle that \n",
    "    # minimizes angular distance from brain-tail angle\n",
    "    which_angle = argmin([abs(angle_difference(brain_tail_angle, candidate)) for candidate in candidate_phis])\n",
    "    #which_angle = argmin(abs(candidate_phis - brain_tail_angle) % (2 * np.pi))\n",
    "    phi = candidate_phis[which_angle]\n",
    "    \n",
    "    # todo: perform rotation on a cropped region of the image\n",
    "    result = rotate(im_, angle=rad2deg(phi), center = (x_, y_))\n",
    "    \n",
    "    # shift resulting image to center of field of view\n",
    "    dydx = (result.shape[0]/2)  - y_, (result.shape[1]/2) - x_\n",
    "    # for performance, avoid sub-pixel shift\n",
    "    result_shifted = roll(result, round(dydx).astype('int'), axis=(0,1))\n",
    "    \n",
    "    if return_sparse:\n",
    "        result_shifted = coo_matrix(result_shifted)\n",
    "    \n",
    "    return result_shifted, phi, dydx\n",
    "\n",
    "\n",
    "def get_cropped_fish(image, phi, dydx, crop_window):\n",
    "    # given an image, a rotation angle, and a shift, apply the shift, then the rotation, then crop around the\n",
    "    # center of the transformed image and apply a binary mask, returning an image of the fish nervous system on a\n",
    "    # a background of 0s    \n",
    "    from scipy.ndimage import shift\n",
    "    from skimage.transform import rotate\n",
    "    from numpy import roll, round\n",
    "    #shifted = shift(image, dydx, mode='wrap')\n",
    "    shifted = roll(image, round(dydx).astype('int'), axis=(0,1))\n",
    "    rotated = rotate(shifted, angle=np.rad2deg(phi), mode='wrap', preserve_range=True)    \n",
    "    mid = np.array(rotated.shape) // 2 \n",
    "    \n",
    "    window_y, window_x = crop_window\n",
    "\n",
    "    # we take the transpose to cancel the effect of this kind of indexing\n",
    "    crop = rotated[mid[0] + window_y, mid[1] + window_x].T\n",
    "    mask = get_fish_mask(crop, return_sparse=False)\n",
    "    \n",
    "    return (crop * mask).astype('int16')\n",
    "\n",
    "def align_brains(static, moving):\n",
    "    from dipy.align.imaffine import AffineRegistration, AffineMap\n",
    "    from dipy.align.transforms import RigidTransform2D \n",
    "    from scipy.ndimage.measurements import center_of_mass\n",
    "    from scipy.ndimage import affine_transform\n",
    "    from numpy import round, eye, array\n",
    "          \n",
    "    affreg = AffineRegistration(verbosity=0)    \n",
    "    rigid = RigidTransform2D()\n",
    "            \n",
    "    static_, moving_ = static.copy(), moving.copy()\n",
    "    coms = (0,0)   \n",
    "    \n",
    "    static_brain = get_brain(static_, return_sparse=False)\n",
    "    moving_brain = get_brain(moving_, return_sparse=False)\n",
    "    \n",
    "    fill_value = static[static_brain].min()\n",
    "    \n",
    "    if not moving_brain.any():\n",
    "        return moving_, coms, AffineMap(eye(3))\n",
    "    \n",
    "    # isolate region of interest for registration\n",
    "    coms = array(round(center_of_mass(static_brain)).astype('int'))\n",
    "    static_brain_cropped = (static_brain * static)[coms[0] - 20:coms[0] + 20, coms[1] - 30:coms[1] + 30]\n",
    "    moving_brain_cropped = (moving_brain * moving)[coms[0] - 20:coms[0] + 20, coms[1] - 30:coms[1] + 30]\n",
    "        \n",
    "    # set background values to minimum of brain to mitigate effect of masking on registration\n",
    "    static_brain_cropped[static_brain_cropped==0] = static_[static_brain].min()\n",
    "    moving_brain_cropped[moving_brain_cropped==0] = moving_[moving_brain].min()\n",
    "    \n",
    "    # estimate rigid transformation between static and moving\n",
    "    g2w = eye(3)\n",
    "    g2w[:2,-1] = -array(static_brain_cropped.shape) / 2\n",
    "    \n",
    "    params0 = None\n",
    "    starting_affine = None\n",
    "    tx = affreg.optimize(static_brain_cropped, moving_brain_cropped, rigid, params0, static_grid2world=g2w, moving_grid2world=g2w, starting_affine=starting_affine)\n",
    "    \n",
    "    dydx = tx.affine[:2,-1]\n",
    "    moving_[moving_ == moving_.min()] = fill_value\n",
    "    tx.domain_grid2world[:2,-1] = -coms\n",
    "    warped = tx.transform(moving_, sampling_grid_shape=(moving_.shape))\n",
    "    return warped, coms, tx\n",
    "\n",
    "def get_tail_angle(images, center, radius):\n",
    "    from skimage.draw import circle_perimeter    \n",
    "    from numpy import arctan2, argsort, pi, argmax, unwrap, arange\n",
    "    \n",
    "    cent_y, cent_x = center\n",
    "    \n",
    "    x_c, y_c = circle_perimeter(cent_x, cent_y, radius=radius, shape = images[-1].shape)\n",
    "    angles = arctan2(y_c - cent_y, x_c - cent_x)\n",
    "    inds = np.argsort(angles)\n",
    "    #keep = inds[arange(-25,25, dtype='int')]\n",
    "    keep = inds\n",
    "    x_tail = x_c[keep]\n",
    "    y_tail = y_c[keep]\n",
    "    tail_arc = images[:, y_tail, x_tail]\n",
    "    tail_angle = argmax(tail_arc, axis=1)\n",
    "    tail_angle = unwrap(angles[keep][tail_angle]) + pi\n",
    "    tail_angle = tail_angle.astype('float32')\n",
    "    \n",
    "    return tail_angle, (x_tail, y_tail), angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# area of the brain in pixels\n",
    "min_brain_size = 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get fish masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.3 s, sys: 15.2 s, total: 28.4 s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fish_masks = np.array(pool_wrapper(get_fish_mask, ims, num_cores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyqtgraph.graphicsWindows.ImageWindow at 0x2ab6c8935828>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmasks = np.array([fm.todense() for fm in fish_masks])\n",
    "pq.image(fmasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check brain segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.81 s, sys: 5.21 s, total: 8.02 s\n",
      "Wall time: 25.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "brain_masks = np.array(pool_wrapper(get_brain, fish_masks, num_cores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyqtgraph.graphicsWindows.ImageWindow at 0x2ab6c8935948>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmasks = np.array([bm.todense() for bm in brain_masks])\n",
    "pq.image(bmasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get oriented masks and coarse transform parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.35 s, sys: 5.42 s, total: 8.77 s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oriented_masks, rotations, translations = zip(*pool_wrapper(orient_tail, fish_masks, num_cores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.285804748535156"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_use()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use transform parameters to generate cropped, masked fish image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.7 s, sys: 18.9 s, total: 33.6 s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# the crop window is relative to the center of mass of the brain\n",
    "window_x = np.arange(-200,40, dtype='int').reshape(-1,1)\n",
    "window_y = np.arange(-100,100)\n",
    "\n",
    "crop_window = [(window_y, window_x)] * len(ims)\n",
    "oriented_ims = np.array(pool_wrapper(get_cropped_fish, zip(ims, rotations, translations, crop_window), num_cores, mode='starmap'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.31112289428711"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.image(oriented_ims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do fine alignment on oriented fish images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.5 s, sys: 20.4 s, total: 29.9 s\n",
      "Wall time: 4min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "static = [oriented_ims[-1]] * oriented_ims.shape[0]\n",
    "aligned_ims, coms, txs = zip(*pool_wrapper(align_brains, zip(static, oriented_ims), num_cores=num_cores, mode='starmap'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pqim = pq.image(np.array(aligned_ims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pqim.roi.getArrayRegion(pqim.image, pqim.imageItem, axes=((1,2)), returnMappedCoords=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wipe_ims(pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this roi works for '/groups/ahrens/ahrenslab/davis/data/epi/20170621/6dpf_cy221xcy221_f2_spon_1/Pos0/'\n",
    "from scipy.ndimage.filters import median_filter\n",
    "roi = (slice(0,None), slice(94,99), slice(190,194))\n",
    "fs_im = 100\n",
    "t = np.arange(oriented_ims.shape[0])[roi[0]] / fs_im\n",
    "fig, axs = plt.subplots(nrows=2, figsize=(12,8))\n",
    "ax_angle = axs[0]\n",
    "ax_angle.plot(t, get_tail_angle(oriented_ims[roi[0]], (100,200), 90)[0], color='grey')\n",
    "ax_angle.set_ylabel('Radians')\n",
    "ts = oriented_ims[roi].mean((1,2))\n",
    "floor_ = 1800\n",
    "ceil_ = None\n",
    "ax_fluo = ax_angle.twinx()\n",
    "#ax_fluo.plot(t, ts.clip(floor_, ceil_), alpha = .4)\n",
    "ax_fluo.plot(t, median_filter(ts, size=200).clip(floor_, ceil_), linewidth=2, color='k', alpha=.7)\n",
    "ax_fluo.set_ylabel('Fluorescence Intensity [au]')\n",
    "axs[0].legend([ax_angle.lines[-1], ax_fluo.lines[-1]], ['Tail angle','Smoothed fluorescence'], )\n",
    "\n",
    "axs[0].set_xlabel('Time [s]')\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "axs[1].imshow(oriented_ims[roi[0]].mean(0), cmap='gray', origin='lower')\n",
    "rect = Rectangle((roi[2].start, roi[1].start), roi[2].stop - roi[2].start, roi[1].stop - roi[1].start, fill=False, color='r')\n",
    "axs[1].add_patch(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test quality of tail orientation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = 21486\n",
    "from scipy.ndimage.measurements import center_of_mass\n",
    "raw_brain = np.array(brain_masks[t].todense())\n",
    "raw_fish = np.array(fish_masks[t].todense())\n",
    "\n",
    "aligned_fish = orient_tail(raw_fish)[0]\n",
    "\n",
    "com_brain = center_of_mass(raw_brain)\n",
    "com_fish = center_of_mass(raw_fish)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(16,9))\n",
    "axs[0].imshow(raw_brain.astype('int') + raw_fish.astype('int'), origin='lower')\n",
    "axs[0].plot(*com_brain[::-1],'o')\n",
    "axs[0].plot(*com_fish[::-1],'o')\n",
    "\n",
    "axs[1].imshow(aligned_fish.todense(), origin='lower')\n",
    "#axs[0].plot(*com_brain[::-1],'o')\n",
    "#axs[0].plot(*com_fish[::-1],'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = -5000\n",
    "test_im = ims[plr[t]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3, figsize=(12,4))\n",
    "from scipy.ndimage import shift\n",
    "from skimage.transform import rotate\n",
    "phi = rotations[t]\n",
    "dydx= translations[t]\n",
    "shifted = shift(test_im, dydx, mode='wrap')\n",
    "rotated = rotate(shifted, angle=np.rad2deg(phi), mode='wrap')\n",
    "\n",
    "axs[0].imshow(test_im, cmap='hsv', origin='lower')\n",
    "axs[1].imshow(shifted, cmap='hsv', origin='lower')\n",
    "axs[2].imshow(rotated, cmap='hsv', origin='lower')\n",
    "axs[2].set_xlim(np.array(rotated.shape) / 2 + [-200,40] )\n",
    "axs[2].set_ylim(np.array(rotated.shape) / 2 + [-100,100] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = -5000\n",
    "plt.imshow(get_cropped_fish(ims[plr[t]], oriented[t][1], oriented[t][-1]), origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pq.image(oriented_ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(9,3))\n",
    "axs.title.set_text('Brain pixels over time')\n",
    "axs.plot(brains.sum((1,2)), color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pq.image(brains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pq.image(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ref = processed[-1]\n",
    "p = Pool(num_cores)\n",
    "tmp = ar(p.map(brain_reg,  zip([ref] * processed.shape[0], processed)));\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aligned_profiles = ar([t[0] for t in tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pq.image(aligned_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.transform import rotate\n",
    "from scipy.ndimage.measurements import center_of_mass\n",
    "moving = rotate(processed[9105], 45)\n",
    "\n",
    "raw_com = np.array(center_of_mass(moving))\n",
    "brain_com = np.array(center_of_mass(get_brain(moving)))    \n",
    "y_, x_ = brain_com\n",
    "\n",
    "fig, axs = plt.subplots(ncols = 2, figsize=(12,4))\n",
    "axs[0].imshow(moving, origin='lower', cmap='gray_r')\n",
    "\n",
    "tail_y, tail_x = raw_com - brain_com\n",
    "brain_tail_angle = np.pi + cart2pol(tail_x, tail_y)[-1]\n",
    "axs[0].arrow(x_, y_, 3 * tail_x, 3 * tail_y, color='y')\n",
    "\n",
    "evals, evecs = eig_wrapper(get_brain(moving, 4, 400))\n",
    "brain_angle = cart2pol(evecs[0,0], evecs[1,0])[-1]\n",
    "\n",
    "axs[0].arrow(x_, y_, evecs[0][0] * np.real(evals[0]), evecs[1][0] * np.real(evals[0]), color='r')\n",
    "axs[0].arrow(x_, y_, evecs[0][1] * np.real(evals[1]), evecs[1][1] * np.real(evals[1]), color='m')\n",
    "axs[0].arrow(x_, y_, tail_x, tail_y)\n",
    "\n",
    "#brain_angle = min(brain_angle, (np.pi + brain_angle) % 2 * np.pi)\n",
    "phi = brain_angle + (brain_angle - brain_tail_angle)\n",
    "phi = min(phi, (np.pi + phi) % 2*np.pi)\n",
    "\n",
    "axs[1].imshow(orient_tail(moving)[0], cmap='gray_r', origin='lower')\n",
    "#axs[1].imshow(rotate(moving, angle=np.rad2deg(phi), center=(x_,y_)), origin='lower', cmap='gray_r')\n",
    "\n",
    "#lims = (x_ - 100, x_ + 100), (y_ - 100, y_ + 100)\n",
    "#[ax.set_xlim(*lims[0]) for ax in axs]\n",
    "#[ax.set_ylim(*lims[1]) for ax in axs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration debugging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage import data_dir\n",
    "from skimage.transform import rotate\n",
    "from numpy import rad2deg\n",
    "from dipy.align.imaffine import AffineRegistration\n",
    "from dipy.align.transforms import RotationTransform2D \n",
    "\n",
    "affreg = AffineRegistration(verbosity=0)\n",
    "rotation = RotationTransform2D()\n",
    "\n",
    "static = imread(data_dir + \"/phantom.png\", as_grey=True)\n",
    "\n",
    "rot_phi = .3\n",
    "moving = rotate(static, rad2deg(rot_phi))\n",
    "mg2w = np.array([[1,0,-moving.shape[0]//2],[0,1,-moving.shape[1]//2],[0,0,1]])\n",
    "sg2w = mg2w\n",
    "params0 = None\n",
    "starting_affine = None\n",
    "tx = affreg.optimize(static, moving, rotation, params0, static_grid2world=sg2w, moving_grid2world=mg2w, starting_affine=starting_affine)\n",
    "titles = ['Static', 'Moving', 'Transformed Moving']\n",
    "\n",
    "samp_g2w = np.eye(3)\n",
    "samp_g2w[0,-1] = -200\n",
    "samp_g2w[1,-1] = -200\n",
    "\n",
    "fig, axs = plt.subplots(ncols = 3)\n",
    "axs[0].imshow(static, origin='lower')\n",
    "axs[1].imshow(moving, origin='lower')\n",
    "axs[2].imshow(tx.transform(moving), origin='lower')\n",
    "[axs[ind].title.set_text(val) for ind, val in enumerate(titles)]\n",
    "\n",
    "print('True angle      : {0}'.format(rot_phi))\n",
    "print('Estimated angle : {0}'.format(np.arccos(tx.affine[0,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dipy.align.imaffine import AffineMap\n",
    "from skimage.transform import AffineTransform\n",
    "from skimage.transform import warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g2ws = np.eye(3)\n",
    "g2ws[0,2] = -(static.shape[0] / 2)\n",
    "g2ws[1,2] = -(static.shape[1] / 2)\n",
    "\n",
    "g2wi = np.eye(3)\n",
    "g2wi[0,2] = -(static.shape[0] / 2) - 100\n",
    "g2wi[1,2] = -(static.shape[0] / 2)\n",
    "\n",
    "affmap_r = AffineMap(np.eye(3))\n",
    "affmap_r.codomain_shape = static.shape\n",
    "affmap_r.domain_shape = static.shape\n",
    "\n",
    "phi = np.pi\n",
    "affmap_r.affine[:2,:2] = rotmat2d(phi)\n",
    "\n",
    "dy, dx = 0,-100\n",
    "affmap_r.affine[0,-1] = dy\n",
    "affmap_r.affine[1,-1] = dx\n",
    "rotated = affmap_r.transform(static, sampling_grid_shape=static.shape, sampling_grid2world=g2ws, image_grid2world=g2wi)\n",
    "\n",
    "affmap_t = AffineMap(np.eye(3))\n",
    "affmap_t.codomain_shape = static.shape\n",
    "affmap_t.domain_shape = static.shape\n",
    "\n",
    "dx, dy = 0,0\n",
    "affmap_t.affine[0,-1] = dx\n",
    "affmap_t.affine[1,-1] = dy\n",
    "\n",
    "translated = affmap_t.transform(rotated, sampling_grid_shape=static.shape, sampling_grid2world = g2ws, image_grid2world=g2wi)\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "axs[0].imshow(static + rotated, origin='lower')\n",
    "axs[1].imshow(static + translated, origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(affine_wrapper(static, affmap.affine[:2,:2], np.array(static.shape) / 2, np.array(static.shape) / 2 + (0,0)), origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = affmap.affine[:2,:2]\n",
    "c_in = np.array(static.shape) / 2\n",
    "c_out = np.array(static.shape) / 2 + (100,100)\n",
    "offset = c_in - c_out.dot(transform)\n",
    "plt.imshow(affine_transform(static, transform.T, offset=offset), origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "from skimage import transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = data.chelsea()[:,:,0]\n",
    "def rotate_and_center(image, rotation_center, phi):\n",
    "    from numpy import array\n",
    "    from skimage.transform import warp, AffineTransform\n",
    "    origin_y, origin_x = rotation_center\n",
    "    shift_y, shift_x = array(image.shape) / 2.\n",
    "    tf_rotate = AffineTransform(rotation=phi)\n",
    "    tf_shift = AffineTransform(translation=[-origin_x, -origin_y])\n",
    "    tf_shift_inv = AffineTransform(translation=[shift_x, shift_y])\n",
    "\n",
    "    image_rotated = transform.warp(image, (tf_shift + (tf_rotate + tf_shift_inv)).inverse)\n",
    "    return image_rotated\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "axs[0].imshow(image, origin='lower')\n",
    "axs[1].imshow(rotate_and_center(image, (100,200), np.pi), origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
